# M4O

The A2C used comes from Stable Baselines 3, and the training environment is Gym. 

The packages required to run the A2C algorithm in the experiments are already listed in the `readme.md` file under the `M4O_indivisible` directory.

The H-PPO-related code is located in "DI-engine-main\dizoo\m4o_hybrid", and to run the H-PPO code, you need to install the required packages first by [pip install requests -i https://mirrors.aliyun.com/pypi/simple/ DI-engine].

The detailed usage of the H-PPO code can be found at: [https://github.com/opendilab/DI-engine].
