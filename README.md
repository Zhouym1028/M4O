# M4O

The A2C used comes from Stable Baselines 3, and the training environment is Gym. 

The packages required to run the A2C algorithm in the experiments are already listed in the `readme.md` file under the `M4O_indivisible` directory.

The H-PPO-related code is located in "DI-engine-main\dizoo\m4o_hybrid", to run the code, you need to execute the `m4o_hybrid_hppo_config.py` file located in `DI-engine-main\dizoo\m4o_hybrid\config`.

The detailed usage of the H-PPO code can be found at: [https://github.com/opendilab/DI-engine], and to run the H-PPO code, you need to install the required packages first by [pip install requests -i https://mirrors.aliyun.com/pypi/simple/ DI-engine].
