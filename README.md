# M4O

The A2C used comes from Stable Baselines 3, and the training environment is Gym. 

The packages required to run the A2C algorithm in the experiments are already listed in the `readme.md` file under the `M4O_indivisible` directory.

The M4O-PO-related code is located in `DI-engine-main\dizoo\m4o_hybrid`, and to run the code, you need to install the required packages first by [pip install requests -i https://mirrors.aliyun.com/pypi/simple/ DI-engine].

The detailed usage of the H-PPO algorithm can be found at: [https://github.com/opendilab/DI-engine].
